:table-caption!:
:toc:
:toclevels: 1
= ECS Deployment

== Requirements

To run this deployment all you need is `docker` and `docker-compose` and the correct `DNS` entries.
Please add these records to your domain name (replace `<ip>` & `<domain>` with the ip and domain name of the machine):

[source,txt]
----
@       IN  A   <ip>
@       IN  MX  1  <domain>.
@       IN  TXT "v=spf1 mx ~all"
_dmarc  IN  TXT "v=DMARC1; p=quarantine"
----

For machines with not a permanent `IP Address` the host will create a entry in `/etc/hosts` with `127.0.1.1 hostname.domain hostname`. This will lead to issues as the docker network uses the name resolver of the host. This leads to the container resolving the hostname of the hostmachine to 127.0.1.1 instead of the ip of the machine. Change the `127.0.1.1` to the `IP Address` of the server.

== Ubuntu Setup

NOTE: This script assumes you are logged in with the user `root`

Install Docker:

[source,bash]
----
curl -fsSL https://get.docker.com | bash
----

Create a user called `ecs` and give him `sudo` without password and `docker` without `sudo`:

[source,bash]
-----
useradd -m -s /bin/bash ecs
echo 'ecs ALL=(ALL) NOPASSWD:ALL' | EDITOR='tee -a' visudo
usermod -aG docker ecs
-----

Create a `alias` for `docker-compose` and write your `ssh-keys`:

[source,bash]
----
su - ecs
echo "alias docker-compose='docker compose'" >> ~/.bashrc
mkdir .ssh
nano .ssh/authorized_keys
----

Close the connection to the server and connect with `ecs`. Clone this repo:

[source,bash]
----
git clone https://github.com/programmierfabrik/ecs-deployment.git ~/deployment
----

=== Github Continuous Delivery

If you want make use of the github pipeline, you will need to add the public key to the `authorized_keys`:

[source,bash]
----
echo "command=\"/home/ecs/deployment/scripts/github-actions.sh \${SSH_ORIGINAL_COMMAND}\" ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIADAgVPUZvANgT9H3yrJJderSno276LnnGl0F9qNCPLo ecs.support@programmierfabrik.at" | sudo tee -a /home/ecs/.ssh/authorized_keys
----

Now you can use this machine with github actions. To add this machine, follow link:#github_actions[these instructions].

=== SSH configuration

We will increase the security over ssh with a few configuration:

[source,bash]
----
cat << EOF | sudo tee -a /etc/ssh/sshd_config.d/ecs.conf
# https://wiki.centos.org/HowTos/Network/SecuringSSH
PermitRootLogin no
AllowUsers ecs
Protocol 2 
PasswordAuthentication no
EOF
sudo service sshd restart 
----

=== Firewall

Only allow traffic for the incoming ports the `ecs` uses:

[source,bash]
----
sudo ufw default allow outgoing
sudo ufw default deny incoming
sudo ufw allow ssh
sudo ufw allow http
sudo ufw allow https
sudo ufw allow smtp
sudo ufw enable
----

== First time setup [[first_time_setup]]

IMPORTANT: This documentation assumes you are in the `/home/ecs/deployment`.

Please follow the order of scripts for the first setup. Otherwise the files will be created in the wrong order.
Create a `.env` file:

[source,bash]
----
./scripts/generate-env.sh domain.name
----

This will generate a `.env` file with the following variables:

.Basic Variables
[cols="1,1,1"]
|===
|Variable Name |Example Value |Description

|TAG
|
|Define which `tag` will be used for `ghcr.io/programmierfabrik/ecs`. See https://github.com/programmierfabrik/ecs/pkgs/container/ecs/versions[tags]

|HOST
|example.com
|This is used for the reverse proxy. With this variable the request is resolved to the correct container with the correct host header. This also make it possible to use `let's encrypt`

|ECS_COMMISSION_UUID
|ecececececececececececececececec
|The `ECS` needs this variable to determine which ethic commission this instance belongs to. See https://ecs-org.github.io/ecs-docs/admin-manual/configuration.html#selecting-the-ethics-commission-uuid[here] for all the `uuids`. Don't forget to set this variable

|ECS_REQUIRE_CLIENT_CERTS
|true
|Whether the admin users need a certificate or not (This should only be `false` in a staging / test environment)


|ECS_USERSWITCHER_ENABLED
|false
|Whether the user switch is enable or disabled (This should only be `true` in a staging environment)

|ECS_EMAIL_ENABLED
|true
|Enable the email traffic via smtp. If false the emails will be printed to the console

|ECS_DISABLE_REGISTER
|false
|If true, disable the registratrion of new users. This way only the invite works and the scripts

|ECS_VOTE_RECEIVERS
|BASG.EKVoten@ages.at
|To which email the vote result of AMG and MPG studies will be sent

|ECS_SENTRY_DSN
|
|Sentry DSN. If errors happen, ecs will report everything to sentry. This includes stack traces, variable, context, request, ...

|BACKUP_URI
|file:///local-backup
|The link:http://duplicity.nongnu.org/vers8/duplicity.1.html#sect7[Duplicity URI] where the backup files will be saved. There always be a `./backup` folder. If this variable is set to `file:///local-backup`, the backups will be saved to this folder. If you want to use `rsync` please refer to link:#rsync_setup[Rsync setup])

|ACME_EMAIL
|ecs.support@programmierfabrik.at
|Let's encrypt will send an email to this person when the certificate is about to expire and when the certificate is refreshed
|===

.Hardcoded Production Variables
[cols="1,1,1"]
|===
|Variable Name |Value |Description

|ECS_PROD
|true
|`Django` sets all the necessary settings for a production environment when `ECS_PROD` is true.

|ECS_DOMAIN
|${HOST}
|Resolves to the `HOST` variable. `Django` needs a `DOMAIN` variable for the `ALLOWED_HOSTS`.

|DATABASE_URL
|postgres://ecs:ecs@database:5432/ecs
|Postgres URI for connecting to the `database` container

|REDIS_URL
|redis://redis:6379/0
|Redis URI for connecting to the `redis` container

|SMTP_URL
|smtp://mailserver:25
|Smtp URI for connecting to the `mailserver` container

|===

.Generated Variables
[cols="1,1"]
|===
|Variable Name |Description

|ECS_SECRET_KEY
|`Django` specific secret key

|ECS_REGISTRATION_SECRET
|`Django` specific secret key

|ECS_PASSWORD_RESET_SECRET
|`Django` specific secret key

|BACKUP_PHASSPHRASE
|Secret key for encrypting backup files

|===

=== Docker network

=== Postgres & Redis

Start the databases:

[source,bash]
----
docker-compose up -d database redis
----

=== ECS

Now we start the main `ecs`. This will apply migrations on start and execute the bootstrap:

IMPORTANT: Wait until the `migration` AND `bootstrap` are finished

[source,bash]
----
docker-compose up -d ecs.web && docker-compose logs -f
----

=== Traefik reverse proxy

No container is connected to the outside world. With the reverse proxy all the needed containers can be exposed:

[source,bash]
----
docker-compose up -d reverse-proxy
----

Now go to your web-browser and open `https://<domain>` so the https certificate is fetched by traefik.

Just to be safe you can check out the content of `acme.json` for your domain:

[source,bash]
----
sudo cat ./data/acme/acme.json
----

=== Mailserver

Next start the mailserver and create a dummy email (`test@<domain>`).
This is needed to generate a `DKIM`. Also configure postfix so it works with bare domains.
As this mailserver is not exposed to the internet and only used for sending mails, the dummy email should not be a security risk:

[source,bash]
----
docker-compose up -d mailserver
. .env && docker exec -e HOST=${HOST} -it ecs_mailserver \
  /bin/bash -c 'echo "test@$HOST|$(doveadm pw -s SHA512-CRYPT -u test@$HOST -p password)" >> /tmp/docker-mailserver/postfix-accounts.cf'
./scripts/setup.sh config dkim
----

=== DKIM

Finally we need to set the `DKIM` record. Execute the following to get the `DKIM` record:

[source,bash]
----
sudo cat ./data/mailserver/config/opendkim/keys/*/mail.txt
----

=== Rest

Start the remaining containers:

[source,bash]
----
docker-compose up -d
----

== Backup

=== Rsync setup [[rsync_setup]]

Almost all of the link:http://duplicity.nongnu.org/vers8/duplicity.1.html#sect7[Duplicity URL Formats] need no extra configuration. This means you can specifiy the `password` & `username` in the URI itself. `rsync over ssh` on the other hand needs a ssh key file. Lets generate a key:

[source,bash]
----
mkdir ./data/.ssh
chmod 700 ./data/.ssh
ssh-keygen -b 4096 -t rsa -f ./data/.ssh/id_rsa -q -N ""
----

Now your backup storage needs to trust this key. If you are using `hetzner` you can use `upload-key-to-hetzner.sh`. If you are using something else, look at the documentation on how to authenticate with ssh keys:

[source,bash]
----
./scripts/upload-key-to-hetzner.sh u123456
----

Now set the `BACKUP_URI`. An example for `hetzner` would be:

[source,bash]
----
BACKUP_URI=rsync://u123456@u123456.your-storagebox.de:23/<./path/to/existing/folder>
----

Rsync is over the port 23 and the path MUST start with `./` and the folder MUST exist.

=== Manual backup

Trigger a backup manually:

[source,bash]
----
docker exec ecs_backup /etc/periodic/daily/jobrunner
----

=== Restore backup

If your data is saved remotely copy it to the `./backup` folder. We will restore the backups to `./restore`:

[source,bash]
----
. .env && docker run --rm \
  -v $PWD/restore:/mnt/backup/src \
  -v $PWD/backup:/backup \
  -e TZ=Europe/Vienna -e DST=file:///backup -e PASSPHRASE=${BACKUP_PASSPHRASE} \
  ghcr.io/tecnativa/docker-duplicity-postgres:v3.0.3 restore
----

After that you can move `./restore/storage-vault` to `./data/ecs/storage-vault` and apply the `sql`:

[source,bash]
----
cat ./restore/dump/ecs.pgdump.gz | gzip -d | \
  docker exec -i ecs_database \
  bash -c "pg_restore -1 -O -F c -n public -d ecs"
mv ./restore/storage-vault/* ./data/ecs/storage-vault/
----

Simple cleanup:

[source,bash]
----
sudo rm -rf backup/ restore/
----

== Scripts

All the scripts are located in `./scripts`.

To create a admin user:

[source,bash]
----
./scripts/create-internal-user.sh email@example.com first_name last_name m|f
----

To create a certificate for a admin user:

[source,bash]
----
./scripts/create-client-certificate.sh email@example.com name_of_cert 365
----

[source,bash]
----
docker exec -it ecs_database psql -U ecs -d ecs
----

== Migrations

=== ecs-deployment to ecs-deployment

You can either copy the `./data` folder and keep everything as is or you copy everything from `./data/ecs` and apply the migration.
Either way you will need `.env` from the old machine.

=== ecs-appliance to ecs-deployment

Generate a `.env` and set the variables based on the `env.yml`. This would include:

* ECS_COMMISSION_UUID
* ECS_SECRET_KEY
* ECS_REGISTRATION_SECRET
* ECS_PASSWORD_RESET_SECRET

Copy the `/data/ecs-pgdump/ecs.pgdump.gz` from the old machine to the new one. This could be done like this:

[source,bash]
----
scp root@old.machine:/data/ecs-pgdump/ecs.pgdump.gz ./
----

Start only the databases and apply the dump from the old machine:

[source,bash]
----
cat ecs.pgdump.gz | gzip -d | \
  docker exec -e PGPASSWORD=ecs -e PGUSER=ecs -i ecs_database \
  bash -c "pg_restore -1 -O -F c -n public -d ecs"
rm ecs.pgdump.gz
----

Create the directory `decrypt` and create the files `vault_encrypt` and `vault_sign` (see `env.yml`). Also copy the `storage-vault` to this folder:

[source,bash]
----
mkdir decrypt
touch decrypt/vault_{encrypt,sign}
# nano decrypt/vault_encrypt
# nano decrypt/vault_sign
rsync -r root@old.machine:/data/ecs-storage-vault/ ./decrypt/storage-vault
----

Now you can start the decrypt process:

[source,bash]
----
./scripts/decrypt-storage-vault.sh
----

Continue with the link:#first_time_setup[first time setup].

After you started ecs.web, all the necessary directories should be generated and we can migrate the `storage-vault`.
Move the `storage-vault` to its proper location and delete all files that were needed for the decryption:

[source,bash]
----
mv ./decrypt/storage-vault/* ./data/ecs/storage-vault
rm -rf ./decrypt/
----

You can also copy the old ca files for the client certificates:

[source,bash]
----
rsync root@old.machine:/app/ecs-ca/* ./data/ecs/ca
----

The System is now migrated and you can finish the link:#first_time_setup[first time setup]!

== Github Actions [[github_actions]]

To add a new machine, edit the `.github/workflows/cd.yml` file. Add a new boolean input under `on.workflow_dispatch.inputs` For a better documentation, see the https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#onworkflow_dispatchinputs[github docs].
