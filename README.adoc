:table-caption!:
:toc:
:toclevels: 1
= ECS Deployment

== Requirements

To run this deployment all you need is `docker` and `docker-compose` and the correct `DNS` entries.
Please add these records to your domain name (replace `<ip>` & `<domain>` with the ip and domain name of the machine):

[source,txt]
----
@       IN  A   <ip>
@       IN  MX  1  <domain>.
@       IN  TXT "v=spf1 mx ~all"
_dmarc  IN  TXT "v=DMARC1; p=quarantine"
----

Also don't forget to set the reverse lookup. Almost all mail services rejects emails if no PTR record is found.

For machines with not a permanent `IP Address` the host will create a entry in `/etc/hosts` with `127.0.1.1 hostname.domain hostname`. This will lead to issues as the docker network uses the name resolver of the host. This leads to the container resolving the hostname of the hostmachine to 127.0.1.1 instead of the ip of the machine. Change the `127.0.1.1` to the `IP Address` of the server.

== Ubuntu Setup

Install Docker:

[source,bash]
----
curl -fsSL https://get.docker.com | bash
----

Create a user called `ecs` and give him `sudo` without password and `docker` without `sudo`:

[source,bash]
-----
useradd -m -s /bin/bash ecs
echo 'ecs ALL=(ALL) NOPASSWD:ALL' | EDITOR='tee -a' visudo
usermod -aG docker ecs
-----

Create a `alias` for `docker-compose` and write your `ssh-keys`:

[source,bash]
----
su - ecs
echo "alias docker-compose='docker compose'" >> ~/.bashrc
mkdir .ssh
nano .ssh/authorized_keys
----

Close the connection to the server and connect with `ecs`. Clone this repo:

[source,bash]
----
git clone https://github.com/programmierfabrik/ecs-deployment.git ~/deployment
----

== Github Continuous Delivery

If you want make use the github pipeline, you will need to setup an extra user:

[source,bash]
----
# Create user with rbash (restricted bash)
sudo useradd -m -s /bin/rbash github
# Change default PATH so the user can only execute commands from /home/github/bin
sudo -u github mkdir /home/github/bin
sudo -u github mkdir /home/github/.ssh
sudo -u github touch /home/github/.ssh/authorized_keys
echo "PATH=/home/github/bin" | sudo tee -a /home/github/.profile
echo "export PATH" | sudo tee -a /home/github/.profile
# Be able to execute sudo as ecs but only for github-actions.sh.
sudo ln -s /bin/sudo /home/github/bin/
echo 'github ALL=(ecs) NOPASSWD:/home/ecs/deployment/scripts/github-actions.sh' | sudo EDITOR='tee -a' visudo
----

NOTE: The reason why we execute github-actions.sh as the user `ecs` is because we need a few basic bash commands but also `docker` / `docker-compose`. And if the user has access to `docker`, no restrict will help as `docker` as executed as root and can override any files with volumes. This way we allow github only to execute our script as the user `ecs` and nothing else.

Now you can use this machine with github actions. To add this machine, follow link:#github_actions[these instructions].

== First time setup [[first_time_setup]]

IMPORTANT: This documentation assumes you are in the `/home/ecs/deployment`.

Please follow the order of scripts for the first setup. Otherwise the files will be created in the wrong order.
Create a `.env` file:

[source,bash]
----
./scripts/generate-env.sh domain.name
----

This will generate a `.env` file with the following variables:

.Basic Variables
[cols="1,1,1"]
|===
|Variable Name |Example Value |Description

|TAG
|
|Define which `tag` will be used for `ghcr.io/programmierfabrik/ecs`. See https://github.com/programmierfabrik/ecs/pkgs/container/ecs/versions[tags]

|HOST
|example.com
|This is used for the reverse proxy. With this variable the request is resolved to the correct container with the correct host header. This also make it possible to use `let's encrypt`

|ECS_COMMISSION_UUID
|ecececececececececececececececec
|The `ECS` needs this variable to determine which ethic commission this instance belongs to. See https://ecs-org.github.io/ecs-docs/admin-manual/configuration.html#selecting-the-ethics-commission-uuid[here] for all the `uuids`. Don't forget to set this variable

|ECS_REQUIRE_CLIENT_CERTS
|true
|whether the admin users need a certificate or not (This should only be `false` in a staging / test environment)


|ECS_USERSWITCHER_ENABLED
|false
|whether the user switch is enable or disabled (This should only be `true` in a staging environment)

|BACKUP_URI
|file:///local-backup
|The link:http://duplicity.nongnu.org/vers8/duplicity.1.html#sect7[Duplicity URI] where the backup files will be saved. There always be a `./backup` folder. If this variable is set to `file:///local-backup`, the backups will be saved to this folder. If you want to use `rsync` please refer to link:#rsync_setup[Rsync setup])

|ACME_EMAIL
|ecs.support@programmierfabrik.at
|Let's encrypt will send an email to this person when the certificate is about to expire and when the certificate is refreshed
|===

.Hardcoded Production Variables
[cols="1,1,1"]
|===
|Variable Name |Value |Description

|ECS_PROD
|true
|`Django` sets all the necessary settings for a production environment when `ECS_PROD` is true.

|ECS_DOMAIN
|${HOST}
|Resolves to the `HOST` variable. `Django` needs a `DOMAIN` variable for the `ALLOWED_HOSTS`.

|DATABASE_URL
|postgres://ecs:ecs@database:5432/ecs
|Postgres URI for connecting to the `database` container

|REDIS_URL
|redis://redis:6379/0
|Redis URI for connecting to the `redis` container

|MEMCACHED_URL
|memcached:11211
|Memcached URI for connecting to the `memcached` container

|SMTP_URL
|smtp://mailserver:25
|Smtp URI for connecting to the `mailserver` container

|===

.Generated Variables
[cols="1,1"]
|===
|Variable Name |Description

|ECS_SECRET_KEY
|`Django` specific secret key

|ECS_REGISTRATION_SECRET
|`Django` specific secret key

|ECS_PASSWORD_RESET_SECRET
|`Django` specific secret key

|===

=== Docker network

=== Postgres, Redis & Memecached databases

Start the databases:

[source,bash]
----
docker-compose up -d database memcached redis
----

=== ECS

Now we start the main `ecs`. This will apply migrations on start and execute the bootstrap:

[source,bash]
----
docker-compose up -d ecs.web
----

=== Traefik reverse proxy

No container is connected to the outside world. With the reverse proxy all the needed containers can be exposed:

[source,bash]
----
docker-compose up -d reverse-proxy
----

Now go to your web-browser and open `https://<domain>` so the https certificate is fetched by traefik.

Just to be safe you can check out the content of `acme.json` for your domain:

[source,bash]
----
sudo cat ./data/acme/acme.json
----

=== Mailserver

Next start the mailserver and create a dummy email (`test@<domain>`).
This is needed to generate a `DKIM`. Also configure postfix so it works with bare domains.
As this mailserver is not exposed to the internet and only used for sending mails, the dummy email should not be a security risk:

[source,bash]
----
docker-compose up -d mailserver
. .env && docker exec -e HOST=${HOST} -it ecs_mailserver \
  /bin/bash -c 'echo "test@$HOST|$(doveadm pw -s SHA512-CRYPT -u test@$HOST -p password)" >> /tmp/docker-mailserver/postfix-accounts.cf'
echo 'mydestination = localhost.$mydomain, localhost' | sudo tee -a ./data/mailserver/config/postfix-main.cf
./scripts/setup.sh config dkim
----

=== DKIM

Finally we need to set the `DKIM` record. Execute the following to get the `DKIM` record:

[source,bash]
----
sudo cat ./data/mailserver/config/opendkim/keys/*/mail.txt
----

=== Rest

Start the remaining containers:

[source,bash]
----
docker-compose up -d
----

== Backup

=== Rsync setup [[rsync_setup]]

Almost all of the link:http://duplicity.nongnu.org/vers8/duplicity.1.html#sect7[Duplicity URL Formats] need no extra configuration. This means you can specifiy the `password` & `username` in the URI itself. `rsync over ssh` on the other hand needs a ssh key file. Lets generate a key:

[source,bash]
----
mkdir ./data/.ssh
chmod 700 ./data/.ssh
ssh-keygen -b 4096 -t rsa -f ./data/.ssh/id_rsa -q -N ""
----

Now your backup storage needs to trust this key. If you are using `hetzner` you can use `upload-key-to-hetzner.sh`. If you are using something else, look at the documentation on how to authenticate with ssh keys:

[source,bash]
----
./scripts/upload-key-to-hetzner.sh u123456
----

Now set the `BACKUP_URI`. An example for `hetzner` would be:

[source,bash]
----
BACKUP_URI=rsync://u123456@u123456.your-storagebox.de:23/<./path/to/existing/folder>
----

Rsync is over the port 23 and the path MUST start with `./` and the folder MUST exist.

=== Manual backup

Trigger a backup manually:

[source,bash]
----
docker exec ecs_backup /etc/periodic/daily/jobrunner
----

=== Restore backup

If your data is saved remotely copy it to the `./backup` folder. We will restore the backups to `./restore`:

[source,bash]
----
docker run --rm \
  -v $PWD/restore:/mnt/backup/src \
  -v $PWD/backup:/backup \
  -e TZ=Europe/Vienna -e OPTIONS=--no-encryption -e DST=file:///backup \
  ghcr.io/tecnativa/docker-duplicity-docker:2.2.0 restore
----

After that you can copy `./restore/storage-vault` to `./data/ecs/storage-vault` and apply the `sql`:

[source,bash]
----
cat ./restore/dump/ecs.pgdump.gz | gzip -d | \
  docker exec -e PGPASSWORD=ecs -e PGUSER=ecs -i ecs_database \
  bash -c "pg_restore -1 -O -F c -n public -d ecs"
mv ./restore/storage-vault/* ./data/ecs/storage-vault/
----

Simple cleanup:

[source,bash]
----
rm -rf backup/ restore/
----

=== Stop backup

To stop the backup for some reason:

[source,bash]
----
docker-compose stop backup
----

=== Start backup

To start it again:

[source,bash]
----
docker-compose start backup
----

== Scripts

All the scripts are located in `./scripts`.

To create a admin user:

[source,bash]
----
./scripts/create-internal-user.sh email@example.com first_name last_name m|f
----

To create a certificate for a admin user:

[source,bash]
----
./scripts/create-client-certificate.sh email@example.com name_of_cert 365
----

== Migrations

=== ecs-deployment to ecs-deployment

Just copy the `.env` and the `./data` folder to the new machine where the `ecs-deployment` is located and start `docker-compose`.

=== ecs-appliance to ecs-deployment

Generate a `.env` and set the variables based on the `env.yml`. This would include:

* HOST
* ECS_COMMISSION_UUID
* ECS_SECRET_KEY
* ECS_REGISTRATION_SECRET
* ECS_PASSWORD_RESET_SECRET

Copy the `/data/ecs-pgdump/ecs.pgdump.gz` from the old machine to the new one. This could be done like this:

[source,bash]
----
scp root@old.machine:/data/ecs-pgdump/ecs.pgdump.gz ./
----

Start the only the databases and apply the dump from the old machine:

[source,bash]
----
cat ecs.pgdump.gz | gzip -d | \
  docker exec -e PGPASSWORD=ecs -e PGUSER=ecs -i ecs_database \
  bash -c "pg_restore -1 -O -F c -n public -d ecs"
----

Continue with the link:#first_time_setup[First time setup]

When you are done, all the directories should be now generated and we can migrate the `storage-vault`.
Create the directory `decrypt` and create the files `vault_encrypt` and `vault_sign` (see `env.yml`). Also copy the `storage-vault` to this folder:

[source,bash]
----
mkdir decrypt
touch vault_encrypt vault_sign
rsync -r root@old.machine:/data/ecs-storage-vault/ ./decrypt/storage-vault
----

Now you can start the decrypt process:

[source,bash]
----
./script/decrypt-storage-vault.sh
----

After it is done, you can move the `storage-vault` to its proper location and delete all files that were needed for the decryption:

[source,bash]
----
mv ./decrypt/storage-vault ./data/ecs/storage-vault
rm -rf ./decrypt/
----

The System is now migrated!

== Github Actions [[github_actions]]

TODO: